---
sidebar_position: 3
title: בינה מלאכותית
---

# מדיניות שימוש בבינה מלאכותית

## 1. מבוא
איי.אמ.אס טכנולוגיות מחויבת לעמידה מלאה בחוקים החלים על השימוש בבינה מלאכותית במדינות בהן היא מספקת מוצרים ושירותים. בנוסף, איי.אמ.אס טכנולוגיות מחויבת לשימוש אתי בבינה מלאכותית. מדיניות זו ("המדיניות") מפרטת את הדרישות של איי.אמ.אס טכנולוגיות בנוגע לאימוץ כל סוגי הבינה המלאכותית בארגון, לרבות לשימוש בייעול עסקי, תפעול, והכללה במוצרים ושירותים של החברה.

מדיניות זו חלה על כל הדירקטורים, הקצינים, חברי המועצה, העובדים, הקבלנים, הנציגים, השותפים והסוכנים של איי.אמ.אס טכנולוגיות, ועל כל אדם או גוף המבצע שירותים בשם החברה. אחראי האכיפה של מדיניות זו בחברה הוא הקצין הממונה על כך.

## 2. הגדרות

- **"בינה מלאכותית" או "AI"** - שימוש בטכנולוגיית למידת מכונה, תוכנה, אוטומציה ואלגוריתמים לביצוע משימות ולקבלת החלטות או תחזיות בהתבסס על מערכי נתונים והנחיות קיימות.
- **"ועדת בינה מלאכותית" או "ועדת AI"** - ועדה פנימית בחברה האחראית על סקירה ואישור של שימושים בבינה מלאכותית בארגון.
- **"מערכת בינה מלאכותית" או "מערכת AI"** - תוכנה המפותחת עם אחת או יותר מהטכניקות והגישות המפורטות בנספח I ויכולה, עבור מטרות מוגדרות על ידי בני אדם, להפיק תוצרים כמו תוכן, תחזיות, המלצות או החלטות המשפיעות על הסביבה שבה היא פועלת.
- **"מערכת AI סגורה"** - מערכת AI בה הקלט הניתן על ידי משתמש אחד משמש לאימון מודל הבינה המלאכותית. נתוני הקלט מבודדים ממשתמשים אחרים, והנתונים נחשבים מאובטחים יותר.
- **"כלי AI משולבים"** - כלים משולבים בתוך תוכנות קיימות שאושרו לשימוש בחברה ואינם דורשים אישור נוסף מוועדת AI לשימוש בהם.
- **"ממשלה"** - ממשלה של מדינה או חלק ממנה.
- **"ישות ממשלתית"** - כל ישות הנשלטת על ידי ממשלה במלואה או בחלקה, לרבות מפעלים מסחריים, מוסדות, סוכנויות, מחלקות, כלי עבודה ציבוריים, כולל מוסדות מחקר ואוניברסיטאות שבבעלות ממשלתית.
- **"פקיד ממשלתי"** - כל קצין או עובד של ישות ממשלתית, פקיד מפלגה פוליטית, מועמד לתפקיד פוליטי, קצינים ועובדים של ארגונים בינלאומיים לא ממשלתיים, וכל אדם האחראי להקצאת כספים ממשלתיים או להשפעה עליהם.
- **"נתונים לא ציבוריים של איי.אמ.אס טכנולוגיות"** - כל מידע שחשיפתו עשויה להפר את פרטיותם של אנשים, להפר חוקים או תקנות, לפגוע במצב הפיננסי של החברה, לפגוע במוניטין שלה, או להפחית את היתרון התחרותי שלה.
- **"מערכת AI פתוחה"** - מערכת AI בה הקלט הניתן על ידי כל המשתמשים משמש לאימון מודל הבינה המלאכותית. נתוני הקלט אינם פרטיים ועשויים להיחשף למשתמשים אחרים.
- **"מידע אישי"** - מידע המזהה, מתאר, או מקושר באופן ישיר או עקיף לאדם או למשק בית מסוים.

## 3. עקרונות מנחים

מדיניות זו נועדה לספק הנחיות כלליות על השימוש בבינה מלאכותית בארגון כדי שהחברה תוכל לנצל את השימוש בבינה מלאכותית ככלי תוך הבטחת עמידה בהתחייבויות משפטיות ופעלת באורח אתי. השימוש בבינה מלאכותית בארגון לא צריך לפגוע בערכי היסוד של החברה או להכניס סיכונים מיותרים לארגון. שימוש בבינה מלאכותית צריך להיות ממוקד בייעול העסק ושיפור יכולת החברה לבצע את משימתה.

חשוב לזכור שאיי.אמ.אס טכנולוגיות היא חברה גלובלית עם ישויות וצוותים ברחבי העולם. לפיכך, מדיניות זו מספקת הנחיות כלליות המבוססות על סטנדרטים גלובליים לשימוש בבינה מלאכותית. יש לקחת בחשבון שהשימוש בבינה מלאכותית במדינות מסוימות עשוי להיות אסור באחרות.

## 4. שימושים אסורים
ישנם שימושים מסוימים בבינה מלאכותית האסורים. למעט אם אושר אחרת על ידי ועדת AI והנהלת המחלקות הרלוונטיות, אוסרים נציגי איי.אמ.אס טכנולוגיות מלעשות שימוש במערכות AI לביצוע כל אחת מהפעילויות הבאות:

- ניהול פעילויות לובינג פוליטי.
- שימוש במערכות AI לזיהוי או מיון תלמידים, מועמדים, עובדים, קבלנים או ישויות קשורות אחרות לפי סטטוס מוגן.
- הכנסת סודות מסחריים, מידע סודי או נתונים אישיים למערכת AI פתוחה.
- הכנסת מידע רגיש על אדם למערכת AI כלשהי.
- שימוש במערכת AI לצורך קבלת ייעוץ משפטי או יצירת קניין רוחני בעל ערך משמעותי לארגון.

## 5. הנחיות אתיות
החברה שואפת לפעול באופן אתי בשימוש בבינה מלאכותית. לפיכך, שימושים בבינה מלאכותית העומדים בדרישות החוקיות עשויים לא לעמוד בדרישות האתיות. יש לוודא שכל שימוש במערכת AI בארגון יעמוד בהנחיות האתיות הבאות:

- **הסכמה מדעת**: לפני הכנסת מידע אישי למערכת AI סגורה, יש לוודא קבלת הסכמה מדעת מהאדם שהמידע האישי שלו יוזן.
- **יושרה בשימוש**: יש להיות כנים לגבי האופן שבו הבינה המלאכותית סייעה בביצוע המשימה.
- **תוכן מתאים**: אין להשתמש במשאבי החברה ליצירת תוכן באמצעות מערכת AI הנחשב לבלתי חוקי, בלתי הולם, מזיק למותג או למוניטין של החברה, או לא מכבד אחרים.

## 6. שימוש בסיכון גבוה במערכות AI
ישנם שימושים מסוימים במערכות AI בעלי סיכון גבוה יותר מאחרים. החברה מחויבת לעמוד בכל דרישות החוק וההנחיות הנוגעות לבינה מלאכותית במדינות בהן היא פועלת. בהתאם לכך, נדרשת זהירות רבה במצבים מסוימים כמו:

- הכנסת נתונים אישיים למערכת AI סגורה.
- מיון מועמדים לעבודה.
- החלטות הקשורות לכוח אדם.
- החלטות הקשורות לרישום מוסדות אקדמיים.
- הערכת תלמידים.

## 7. סטנדרטים כלליים לשימוש במערכות AI ואישור שימוש
למעט כלים משולבים במערכות שאושרו, כל שימוש במערכות AI חייב באישור מוועדת AI לפני השימוש, כדי לוודא שהשימוש עומד בעקרונות הבאים:

- **חוקיות**: השימוש במערכות AI חייב לעמוד בכל החוקים והתקנות החלים, כמו גם בכל התחייבות חוזית.
- **אתיות**: השימוש במערכות AI חייב לעמוד בעקרונות אתיים, להיות הוגן ולהימנע מהטיה.
- **שקיפות**: חייבים להיות יעדים ברורים לשימוש במערכת AI ופיקוח מתועד על השימוש.
- **הכרחיות**: השימוש במערכות AI חייב להיות למטרה עסקית תקפה.

## 8. הכשרה 
כל נציגי החברה המשתמשים במערכות AI חייבים לעבור הכשרה על מדיניות זו.

## 9. דיווח על אי-ציות 
נציגי החברה מודעים לכל התנהגות העלולה להפר מדיניות זו נדרשים לדווח עליה. הדיווחים ייחקרו על ידי ועדת AI, יועץ משפטי, מחלקת משאבי אנוש או גורמים רלוונטיים אחרים. עובד שמפר את המדיניות עלול לעמוד בפני סנקציות משמעתיות, עד ובכלל סיום העסקתו.


## נספח I: טכניקות ושיטות בינה מלאכותית

- **גישות ללמידת מכונה**: כולל למידה מונחית, למידה בלתי מונחית ולמידת חיזוק, תוך שימוש במגוון רחב של שיטות, כולל למידה עמוקה.
- **גישות מבוססות לוגיקה וידע**: כולל ייצוג ידע, תכנות לוגי אינדוקטיבי, בסיסי ידע, הנמקה דדוקטיבית, מערכות מומחים, והסקה לוגית.
- **גישות סטטיסטיות**: כולל אמידה בייסיאנית, חיפוש ושיטות אופטימיזציה.

## נספח II: דרישות למערכות AI בסיכון גבוה (באיחוד האירופי)

הדרישות חלות על מערכות AI בסיכון גבוה בנוגע לאיכות מערכי הנתונים שבהם נעשה שימוש, תיעוד טכני ושמירת רשומות, שקיפות, אספקת מידע למשתמשים, פיקוח אנושי, עמידות, דיוק ואבטחת סייבר. דרישות אלו נחוצות כדי להפחית ביעילות את הסיכונים לבריאות, בטיחות וזכויות יסוד, בהתאם למטרת המערכת. איכות גבוהה של מערכי הנתונים היא חיונית לביצועים של מערכות AI רבות, במיוחד כשמדובר בשיטות אימון של מודלים, כדי להבטיח שהמערכת בסיכון גבוה פועלת כמתוכנן ובבטיחות, ושאינה הופכת למקור לאפליה האסורה לפי חוקי האיחוד האירופי.

מערכי נתונים לאימון, אימות ובדיקות צריכים להיות רלוונטיים, מייצגים, נקיים מטעויות ושלמים, בהתאם למטרת המערכת. עליהם לכלול את המאפיינים הסטטיסטיים המתאימים, כולל ביחס לאנשים או קבוצות שעליהם המערכת מיועדת לפעול. כדי להגן על זכויותיהם של אחרים מפני אפליה הנובעת מהטיה במערכות AI, על הספקים להיות מסוגלים לעבד גם קטגוריות מיוחדות של נתונים אישיים, מטעמי עניין ציבורי משמעותי, כדי להבטיח ניטור, זיהוי ותיקון של הטיות במערכות AI בסיכון גבוה.

לצורך פיתוח מערכות AI בסיכון גבוה, יש להבטיח גישה למערכי נתונים איכותיים על ידי ספקים, גופים מאושרים וישויות רלוונטיות אחרות, כמו מרכזי חדשנות דיגיטלית, מתקני בדיקה וניסויים, וחוקרים. חללי נתונים משותפים באיחוד האירופי יקלו על גישה לא מפלה לנתונים איכותיים לצורך אימון, אימות ובדיקת מערכות AI, תוך שמירה על פרטיות ואבטחה.

## נספח III: סוגי מערכות AI בסיכון גבוה

- מערכות זיהוי ביומטרי מרחוק בזמן אמת ולאחר מכן, שיהיו כפופות לדרישות מיוחדות לגבי יכולות רישום ופיקוח אנושי.
- מערכות AI המשמשות בתחום החינוך או ההכשרה המקצועית, בעיקר לצורך קביעת גישה או הקצאה למוסדות חינוכיים או להכשרה מקצועית, או להערכת אנשים במבחנים כחלק או כתנאי ללימודיהם.
- מערכות AI המשמשות בתעסוקה, ניהול עובדים וגישה לעבודה עצמאית, בעיקר לצורך גיוס ובחירת אנשים, קבלת החלטות על קידום או פיטורים, והקצאת משימות, מעקב או הערכת אנשים בהקשרים של יחסי עבודה.
- גישה לשירותים פרטיים וציבוריים חיוניים והנאה מהם, המאפשרים לאנשים להשתתף בחברה או לשפר את רמת החיים שלהם. מערכות AI המשמשות להערכת ציון אשראי או כושר האשראי של אנשים פרטיים.

מקור: [P9_TA(2024)0138 Artificial Intelligence Act](https://www.europarl.europa.eu/doceo/document/TA-9-2024-0138_EN.pdf)